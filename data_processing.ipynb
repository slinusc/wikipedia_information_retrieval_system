{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing the JSON file line by line...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing lines:   5%|▌         | 139425/2606260 [00:17<31:06, 1321.86line/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 0 written to data/arxiv-metadata-oai-snapshot_chunks\\chunk_0.json (200.00 MB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing lines:  10%|█         | 272151/2606260 [00:37<45:12, 860.41line/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1 written to data/arxiv-metadata-oai-snapshot_chunks\\chunk_1.json (200.00 MB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing lines:  15%|█▌        | 398938/2606260 [00:57<23:41, 1553.26line/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 2 written to data/arxiv-metadata-oai-snapshot_chunks\\chunk_2.json (200.00 MB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing lines:  20%|█▉        | 519796/2606260 [01:12<24:18, 1430.52line/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 3 written to data/arxiv-metadata-oai-snapshot_chunks\\chunk_3.json (200.00 MB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing lines:  24%|██▍       | 638119/2606260 [01:18<01:12, 27080.27line/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 4 written to data/arxiv-metadata-oai-snapshot_chunks\\chunk_4.json (200.00 MB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing lines:  29%|██▉       | 764542/2606260 [01:45<22:28, 1366.23line/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 5 written to data/arxiv-metadata-oai-snapshot_chunks\\chunk_5.json (200.00 MB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing lines:  34%|███▍      | 883679/2606260 [02:01<17:24, 1649.81line/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 6 written to data/arxiv-metadata-oai-snapshot_chunks\\chunk_6.json (200.00 MB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing lines:  38%|███▊      | 992503/2606260 [02:06<00:57, 28052.71line/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 7 written to data/arxiv-metadata-oai-snapshot_chunks\\chunk_7.json (200.00 MB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing lines:  43%|████▎     | 1112068/2606260 [02:34<23:47, 1046.97line/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 8 written to data/arxiv-metadata-oai-snapshot_chunks\\chunk_8.json (200.00 MB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing lines:  47%|████▋     | 1228555/2606260 [02:52<21:06, 1088.10line/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 9 written to data/arxiv-metadata-oai-snapshot_chunks\\chunk_9.json (200.00 MB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing lines:  52%|█████▏    | 1342681/2606260 [03:06<12:10, 1729.77line/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 10 written to data/arxiv-metadata-oai-snapshot_chunks\\chunk_10.json (200.00 MB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing lines:  56%|█████▌    | 1453167/2606260 [03:20<12:06, 1586.56line/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 11 written to data/arxiv-metadata-oai-snapshot_chunks\\chunk_11.json (200.00 MB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing lines:  60%|██████    | 1564715/2606260 [03:34<11:29, 1509.98line/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 12 written to data/arxiv-metadata-oai-snapshot_chunks\\chunk_12.json (200.00 MB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing lines:  64%|██████▍   | 1672088/2606260 [04:00<26:14, 593.37line/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 13 written to data/arxiv-metadata-oai-snapshot_chunks\\chunk_13.json (200.00 MB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing lines:  68%|██████▊   | 1784484/2606260 [04:35<32:02, 427.41line/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 14 written to data/arxiv-metadata-oai-snapshot_chunks\\chunk_14.json (200.00 MB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing lines:  73%|███████▎  | 1894287/2606260 [05:00<19:21, 612.91line/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 15 written to data/arxiv-metadata-oai-snapshot_chunks\\chunk_15.json (200.00 MB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing lines:  77%|███████▋  | 1999750/2606260 [05:24<20:16, 498.41line/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 16 written to data/arxiv-metadata-oai-snapshot_chunks\\chunk_16.json (200.00 MB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing lines:  81%|████████  | 2108146/2606260 [06:10<1:09:11, 119.98line/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 17 written to data/arxiv-metadata-oai-snapshot_chunks\\chunk_17.json (200.00 MB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing lines:  85%|████████▌ | 2218310/2606260 [06:42<00:59, 6547.44line/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 18 written to data/arxiv-metadata-oai-snapshot_chunks\\chunk_18.json (200.00 MB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing lines:  90%|█████████ | 2349226/2606260 [07:44<29:50, 143.57line/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 19 written to data/arxiv-metadata-oai-snapshot_chunks\\chunk_19.json (200.00 MB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing lines:  96%|█████████▋| 2508599/2606260 [08:35<11:43, 138.81line/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 20 written to data/arxiv-metadata-oai-snapshot_chunks\\chunk_20.json (200.00 MB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing lines: 100%|██████████| 2606260/2606260 [08:49<00:00, 4920.97line/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 21 written to data/arxiv-metadata-oai-snapshot_chunks\\chunk_21.json (122.78 MB)\n",
      "Splitting completed.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "def split_json(file_path, chunk_size_mb=200):\n",
    "    # Calculate the chunk size in bytes\n",
    "    chunk_size = chunk_size_mb * 1024 * 1024\n",
    "\n",
    "    # Ensure the file exists\n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"File {file_path} not found.\")\n",
    "        return\n",
    "\n",
    "    # Create a directory for the output chunks\n",
    "    output_dir = os.path.splitext(file_path)[0] + \"_chunks\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Initialize variables for chunking\n",
    "    current_chunk = []\n",
    "    current_size = 0\n",
    "    chunk_index = 0\n",
    "\n",
    "    # Read and process the NDJSON file line by line\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        print(\"Processing the JSON file line by line...\")\n",
    "        lines = file.readlines()  # Get all lines\n",
    "        total_lines = len(lines)  # Total number of JSON objects\n",
    "\n",
    "        # Set up the progress bar\n",
    "        with tqdm(total=total_lines, desc=\"Processing lines\", unit=\"line\") as pbar:\n",
    "            for line in lines:\n",
    "                try:\n",
    "                    # Parse the JSON object from the current line\n",
    "                    json_obj = json.loads(line)\n",
    "                except json.JSONDecodeError as e:\n",
    "                    print(f\"Skipping malformed line: {e}\")\n",
    "                    pbar.update(1)\n",
    "                    continue\n",
    "\n",
    "                # Serialize the object to calculate its size\n",
    "                json_str = json.dumps(json_obj)\n",
    "                json_size = len(json_str.encode(\"utf-8\"))\n",
    "\n",
    "                # Check if adding this object exceeds the chunk size\n",
    "                if current_size + json_size > chunk_size:\n",
    "                    # Write the current chunk to a file\n",
    "                    output_file = os.path.join(output_dir, f\"chunk_{chunk_index}.json\")\n",
    "                    with open(output_file, \"w\", encoding=\"utf-8\") as chunk_file:\n",
    "                        json.dump(current_chunk, chunk_file, indent=4)\n",
    "                    print(f\"Chunk {chunk_index} written to {output_file} ({current_size / (1024 * 1024):.2f} MB)\")\n",
    "\n",
    "                    # Reset for the next chunk\n",
    "                    current_chunk = []\n",
    "                    current_size = 0\n",
    "                    chunk_index += 1\n",
    "\n",
    "                # Add the object to the current chunk\n",
    "                current_chunk.append(json_obj)\n",
    "                current_size += json_size\n",
    "\n",
    "                # Update the progress bar\n",
    "                pbar.update(1)\n",
    "\n",
    "        # Write the last chunk if it contains any remaining data\n",
    "        if current_chunk:\n",
    "            output_file = os.path.join(output_dir, f\"chunk_{chunk_index}.json\")\n",
    "            with open(output_file, \"w\", encoding=\"utf-8\") as chunk_file:\n",
    "                json.dump(current_chunk, chunk_file, indent=4)\n",
    "            print(f\"Chunk {chunk_index} written to {output_file} ({current_size / (1024 * 1024):.2f} MB)\")\n",
    "\n",
    "    print(\"Splitting completed.\")\n",
    "\n",
    "# Example usage\n",
    "large_json_file = \"data/arxiv-metadata-oai-snapshot.json\"  # Replace with the path to your JSON file\n",
    "split_json(large_json_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first document has the similarity score: -6.033543109893799\n",
      "The second document has the similarity score: -6.910589694976807\n",
      "The third document has the similarity score: 2.7864646911621094\n",
      "The document with the highest similarity score is document 3 with a score of 2.79\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained('cross-encoder/ms-marco-TinyBERT-L-2')\n",
    "tokenizer = AutoTokenizer.from_pretrained('cross-encoder/ms-marco-TinyBERT-L-2')\n",
    "\n",
    "features = tokenizer([\"Who was John of Gaunt's brother, and what was his role in government?\", \"Who was John of Gaunt's brother, and what was his role in government?\", \"Who was John of Gaunt's brother, and what was his role in government?\"],\n",
    "                     [\"External links Richard II's Treasure from the Institute of Historical Research and Royal Holloway, University of London. Richard II's Irish chancery rolls listed by year, translated, published online by CIRCLE. The Peasants' Revolt, BBC Radio 4 discussion with Miri Rubin, Caroline Barron & Alastair Dunn (In Our Time, 16 November 2006) |- 1367 births 1400 deaths 14th-century English monarchs 14th-century murdered monarchs 14th-century English nobility Burials at Westminster Abbey Deaths by starvation Dukes of Cornwall English people of French descent English pretenders to the French throne English Roman Catholics House of Plantagenet Knights of the Garter Medieval child rulers Monarchs who abdicated Peasants' Revolt People from Bordeaux Princes of Wales Prisoners in the Tower of London Peers created by Edward III Children of Edward the Black Prince\", \n",
    "                      \"References Sources Chronicles (1993) Chronicles of the Revolution, 1397\\u20131400: The Reign of Richard II, ed. Chris Given-Wilson. Manchester: Manchester University Press. . Froissart, Jean (1978). Chronicles, ed. Geoffrey Brereton. London: Penguin. . (1977) Historia Vitae et Regni Ricardi Secundi, ed. George B. Stow. Philadelphia: University of Pennsylvania Press. . Knighton, Henry (1995). Knighton's Chronicle 1337\\u20131396, ed. G. H. Martin. Oxford: Clarendon Press. . Walsingham, Thomas (1862\\u201364). Historia Anglicana 2 vols., ed. Henry Thomas Riley. London: Longman, Roberts, and Green Secondary sources Alexander, Jonathan; Binski, Paul (eds.) (1987). Age of Chivalry, Art in Plantagenet England, 1200\\u20131400. London: Royal Academy/Weidenfeld & Nicolson. Levey, Michael (1971). Painting at Court. London: Weidenfeld and Nicolson. External links\", \n",
    "                      \"John of Gaunt's brother Edmund of Langley was only one year younger, but it has been suggested that this prince was of \\\"limited ability\\\", and he took less part in government than Gaunt did. b. It has been speculated that the whole incident surrounding the killing of Wat Tyler was in fact planned in advance by the council, in order to end the rebellion. c. While both England and the Empire supported Pope Urban VI in Rome, the French sided with the Avignon Papacy of Clement VII. d. This \\\"appeal\\\"which would give its name to the Lords Appellantwas not an appeal in the modern sense of an application to a higher authority. In medieval common law the appeal was criminal charge, often one of treason.\"],\n",
    "                      return_tensors='pt', padding=True)\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    scores = model(**features).logits\n",
    "    print(\"The first document has the similarity score:\", scores[0][0].item())\n",
    "    print(\"The second document has the similarity score:\", scores[1][0].item())\n",
    "    print(\"The third document has the similarity score:\", scores[2][0].item())\n",
    "\n",
    "# determine the highest similarity score and wich document it belongs to\n",
    "\n",
    "similarity_scores = [scores[0][0].item(), scores[1][0].item(), scores[2][0].item()]\n",
    "max_score = max(similarity_scores)\n",
    "max_score_index = similarity_scores.index(max_score)\n",
    "\n",
    "print(f\"The document with the highest similarity score is document {max_score_index + 1} with a score of {max_score:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open parquet file\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load the data from the Parquet file\n",
    "\n",
    "df = pd.read_parquet(\"C:/Users/linus/Downloads/a.parquet/a.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>categories</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>442721</th>\n",
       "      <td>73426511</td>\n",
       "      <td>A‘ea‘e (group)</td>\n",
       "      <td>A‘ea‘e is a Hawaiian music group composed of K...</td>\n",
       "      <td>[Hawaiian music, 2022 in music]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>442722</th>\n",
       "      <td>15845764</td>\n",
       "      <td>A∞-operad</td>\n",
       "      <td>In the theory of operads in algebra and algebr...</td>\n",
       "      <td>[Abstract algebra, Algebraic topology]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>442723</th>\n",
       "      <td>15156877</td>\n",
       "      <td>A♭ (musical note)</td>\n",
       "      <td>A (A-flat; also called la bémol) is the ninth ...</td>\n",
       "      <td>[Musical notes]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>442724</th>\n",
       "      <td>2994338</td>\n",
       "      <td>A♯ (Axiom)</td>\n",
       "      <td>A♯ (pronounced: A sharp) is an object-oriented...</td>\n",
       "      <td>[Functional languages, Discontinued programmin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>442725</th>\n",
       "      <td>22858655</td>\n",
       "      <td>A♯1 Roller Rager</td>\n",
       "      <td>\"A#1 Roller Rager\" is a song by American rock ...</td>\n",
       "      <td>[2009 singles, CKY (band) songs, 2009 songs, R...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              id              title  \\\n",
       "442721  73426511     A‘ea‘e (group)   \n",
       "442722  15845764          A∞-operad   \n",
       "442723  15156877  A♭ (musical note)   \n",
       "442724   2994338         A♯ (Axiom)   \n",
       "442725  22858655   A♯1 Roller Rager   \n",
       "\n",
       "                                                     text  \\\n",
       "442721  A‘ea‘e is a Hawaiian music group composed of K...   \n",
       "442722  In the theory of operads in algebra and algebr...   \n",
       "442723  A (A-flat; also called la bémol) is the ninth ...   \n",
       "442724  A♯ (pronounced: A sharp) is an object-oriented...   \n",
       "442725  \"A#1 Roller Rager\" is a song by American rock ...   \n",
       "\n",
       "                                               categories  \n",
       "442721                    [Hawaiian music, 2022 in music]  \n",
       "442722             [Abstract algebra, Algebraic topology]  \n",
       "442723                                    [Musical notes]  \n",
       "442724  [Functional languages, Discontinued programmin...  \n",
       "442725  [2009 singles, CKY (band) songs, 2009 songs, R...  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
